{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Sampled 503 positive and 503 negative edges. **\n"
     ]
    }
   ],
   "source": [
    "from stellargraph.data import EdgeSplitter\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import multiprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from stellargraph.data import BiasedRandomWalk\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import stellargraph as sg\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import plot\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "used_params = {\n",
    "    'p': 1.0,\n",
    "    'q': 0.6,\n",
    "    'dimensions': 128,\n",
    "    'num_walks': 100,\n",
    "    'walk_length': 30,\n",
    "    'window_size': 13,\n",
    "    'num_iter': 5,\n",
    "    'workers': multiprocessing.cpu_count()\n",
    "}\n",
    "\n",
    "def create_mapping(file_content):\n",
    "    # Convert the uploaded file content to a string\n",
    "    text = file_content.decode('utf-8')\n",
    "\n",
    "    # Feldolgozom a sorokat\n",
    "    connections = []\n",
    "    from_list = []\n",
    "    to_list = []\n",
    "    for row in text.split('\\n')[:-1]:\n",
    "        a, b = [int(x) for x in row.split(' ')]\n",
    "        connections.append((a, b))\n",
    "\n",
    "        from_list.append(a)\n",
    "        to_list.append(b)\n",
    "\n",
    "    id_mapper = {}\n",
    "    reverse_id_mapper = {}\n",
    "    counter = 0\n",
    "    for elem in from_list:\n",
    "        if elem not in id_mapper.values():\n",
    "            id_mapper[counter] = elem\n",
    "            reverse_id_mapper[elem] = counter\n",
    "            counter += 1\n",
    "\n",
    "    for elem in to_list:\n",
    "        if elem not in id_mapper.values():\n",
    "            id_mapper[counter] = elem\n",
    "            reverse_id_mapper[elem] = counter\n",
    "            counter += 1\n",
    "\n",
    "    scaled_connections = []\n",
    "    for first, second in connections:\n",
    "        first_scaled = reverse_id_mapper[first]\n",
    "        second_scaled = reverse_id_mapper[second]\n",
    "\n",
    "        scaled_connections.append((first_scaled, second_scaled))\n",
    "\n",
    "    return scaled_connections, id_mapper, reverse_id_mapper\n",
    "\n",
    "def create_graph(connections):\n",
    "    graph = nx.Graph()\n",
    "    graph.add_edges_from(connections)\n",
    "    graph = sg.StellarGraph.from_networkx(graph)\n",
    "\n",
    "    return graph\n",
    "\n",
    "def node2vec_embedding(graph, name):\n",
    "    rw = BiasedRandomWalk(graph)\n",
    "    walks = rw.run(graph.nodes(), n=used_params['num_walks'], length=used_params['walk_length'], p=used_params['p'], q=used_params['q'])\n",
    "    print(f\"Number of random walks for '{name}': {len(walks)}\")\n",
    "\n",
    "    model = Word2Vec(\n",
    "        walks,\n",
    "        vector_size=used_params['dimensions'],\n",
    "        window=used_params['window_size'],\n",
    "        min_count=0,\n",
    "        sg=1,\n",
    "        workers=used_params['workers'],\n",
    "        epochs=used_params['num_iter'],\n",
    "    )\n",
    "\n",
    "    def get_embedding(u):\n",
    "        return model.wv[u]\n",
    "\n",
    "    return get_embedding\n",
    "\n",
    "def operator_l2(u, v):\n",
    "    return (u - v) ** 2\n",
    "\n",
    "\n",
    "def link_prediction_classifier(max_iter=4000):\n",
    "    lr_clf = LogisticRegressionCV(Cs=10, cv=10, scoring=\"roc_auc\", max_iter=max_iter)\n",
    "    return Pipeline(steps=[(\"sc\", StandardScaler()), (\"clf\", lr_clf)])\n",
    "\n",
    "def link_examples_to_features(link_examples, transform_node, binary_operator):\n",
    "    return [\n",
    "        binary_operator(transform_node(src), transform_node(dst))\n",
    "        for src, dst in link_examples]\n",
    "\n",
    "def train_link_prediction_model(\n",
    "        link_examples, link_labels, get_embedding, binary_operator\n",
    "):\n",
    "    # Ezt akár lehet módosítani is más algoritmussal\n",
    "    clf = link_prediction_classifier()\n",
    "\n",
    "    # Itt távolságot számol a start és end pont embeddingje között\n",
    "    link_features = link_examples_to_features(\n",
    "        link_examples, get_embedding, binary_operator\n",
    "    )\n",
    "    # Majd arra fitteli a modelt\n",
    "    clf.fit(link_features, link_labels)\n",
    "    return clf\n",
    "\n",
    "def create_result_df(graph, model, embedding, operator):\n",
    "    nodes = list(graph.nodes())\n",
    "    nodes.sort()\n",
    "\n",
    "    first_node = []\n",
    "    second_node = []\n",
    "    for node1 in nodes:\n",
    "        for node2 in nodes:\n",
    "            if node1 < node2:\n",
    "                first_node.append(node1)\n",
    "                second_node.append(node2)\n",
    "\n",
    "\n",
    "    prob_df = pd.DataFrame({'first_node': first_node, 'second_node': second_node})\n",
    "    processed_tmp = link_examples_to_features(prob_df.values, embedding, operator)\n",
    "\n",
    "    prob_df['prob'] = model.predict_proba(processed_tmp)[:,1]\n",
    "    prob_df['pred_class'] = model.predict(processed_tmp)\n",
    "\n",
    "    prob_df = prob_df.set_index(['first_node', 'second_node'])\n",
    "\n",
    "    graph_edges = [(min(u, v), max(u, v)) for u, v in G.edges()]\n",
    "    graph_df = pd.DataFrame(graph_edges, columns=['first_node', 'second_node'])\n",
    "\n",
    "    graph_df = graph_df.set_index(['first_node', 'second_node'])\n",
    "\n",
    "    graph_df['edge'] = 1\n",
    "\n",
    "    result_df = prob_df.join(graph_df, how = 'left')\n",
    "    result_df['edge'] = result_df['edge'].fillna(0)\n",
    "    result_df['pred_edge'] = result_df['prob'].apply(lambda x: 1 if x > 0.5 else 0)\n",
    "\n",
    "\n",
    "    return result_df\n",
    "\n",
    "def plot_confusion_matrix(df, real, predicted):\n",
    "    cm = confusion_matrix(df[real], df[predicted])\n",
    "\n",
    "    class_labels = ['Negative Edge', 'Edge']\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_labels))\n",
    "    plt.xticks(tick_marks, class_labels, rotation=45)\n",
    "    plt.yticks(tick_marks, class_labels)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "\n",
    "    for i in range(len(class_labels)):\n",
    "        for j in range(len(class_labels)):\n",
    "            plt.text(j, i, cm[i, j], ha='center', va='center', color='white' if cm[i, j] > cm.max() / 2 else 'black')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_roc_curve(predictions_df):\n",
    "    # Extract the 'Real', 'Pred', and 'Prob' columns\n",
    "    ground_truth_values = predictions_df['edge'].tolist()\n",
    "    predictions = predictions_df['pred_edge'].tolist()\n",
    "\n",
    "    # Calculate the ROC curve\n",
    "    fpr, tpr, _ = roc_curve(ground_truth_values, predictions)\n",
    "\n",
    "    # Calculate the AUC (Area Under the Curve)\n",
    "    roc_auc = roc_auc_score(ground_truth_values, predictions)\n",
    "\n",
    "    # Plot the ROC curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "def plot_histogram(df):\n",
    "    plt.figure(figsize=(10, 6))  # Set the figure size\n",
    "    plt.hist(df.prob, bins=30, color='skyblue', edgecolor='black', alpha=0.7)  # Customize histogram appearance\n",
    "    plt.title('Probability Distribution Histogram')  # Set the title\n",
    "    plt.xlabel('Probability')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)  # Add grid lines\n",
    "    plt.show()\n",
    "\n",
    "def read_graph_a(path, map = True):\n",
    "    id_mapper_ = None\n",
    "    reverse_id_mapper_ = None\n",
    "\n",
    "    if map:\n",
    "        id_mapper_, reverse_id_mapper_, edges = create_mapping_a(path)\n",
    "        G_ = nx.Graph()\n",
    "        G_.add_edges_from(edges)\n",
    "    else:\n",
    "        G_ = nx.read_edgelist(path, nodetype=int, create_using=nx.Graph())\n",
    "\n",
    "    G_ = sg.StellarGraph.from_networkx(G_)\n",
    "\n",
    "    return G_, id_mapper_, reverse_id_mapper_\n",
    "\n",
    "def create_mapping_a(path):\n",
    "    with open(path, 'rt') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Feldolgozom a sorokat\n",
    "    connections = []\n",
    "    from_list = []\n",
    "    to_list = []\n",
    "    for row in text.split('\\n')[:-1]:\n",
    "        a, b = [int(x) for x in row.split(' ')]\n",
    "        connections.append((a, b))\n",
    "\n",
    "        from_list.append(a)\n",
    "        to_list.append(b)\n",
    "\n",
    "\n",
    "    id_mapper = {}\n",
    "    reverse_id_mapper = {}\n",
    "    counter = 0\n",
    "    for elem in from_list:\n",
    "        if elem not in id_mapper.values():\n",
    "            id_mapper[counter] = elem\n",
    "            reverse_id_mapper[elem] = counter\n",
    "            counter += 1\n",
    "\n",
    "    for elem in to_list:\n",
    "        if elem not in id_mapper.values():\n",
    "            id_mapper[counter] = elem\n",
    "            reverse_id_mapper[elem] = counter\n",
    "            counter += 1\n",
    "\n",
    "    scaled_connections = []\n",
    "    for first, second in connections:\n",
    "        first_scaled = reverse_id_mapper[first]\n",
    "        second_scaled = reverse_id_mapper[second]\n",
    "\n",
    "        scaled_connections.append((first_scaled, second_scaled))\n",
    "\n",
    "    return id_mapper, reverse_id_mapper, scaled_connections\n",
    "\n",
    "\n",
    "\n",
    "# mapper, reverse_mapper, graph_edges = create_mapping(file)\n",
    "G, mapper, reverse_mapper = read_graph_a('facebook/0.edges')\n",
    "# G = create_graph(G_)\n",
    "\n",
    "edge_splitter = EdgeSplitter(G)\n",
    "splitted_graph, X, y = edge_splitter.train_test_split(p=0.2, method=\"global\")\n",
    "\n",
    "embedding_all = node2vec_embedding(splitted_graph, \"Graph\") # TODO: Megkérdezni valaki, hogy G-vel miért nem működik, nem értem\n",
    "\n",
    "model = train_link_prediction_model(X, y, embedding_all, operator_l2)\n",
    "\n",
    "predictions = create_result_df(splitted_graph, model, embedding_all, operator_l2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_histogram(predictions)\n",
    "plot_confusion_matrix(predictions, 'edge', 'pred_edge')\n",
    "plot_roc_curve(predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nx_G = G.to_networkx()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_degree_distribution_log(G):\n",
    "    degree_dict = dict(G.degree())\n",
    "    degree = list(degree_dict.values())\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.hist(degree, bins=30, color='skyblue', edgecolor='black', alpha=0.7, log=True)\n",
    "    plt.title('Degree Distribution Histogram')\n",
    "    plt.xlabel('Degree')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.show()\n",
    "\n",
    "plot_degree_distribution_log(nx_G)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "def calculate_recall(df):\n",
    "    return recall_score(df['edge'], df['pred_edge'])\n",
    "\n",
    "def calculate_precision(df):\n",
    "    return precision_score(df['edge'], df['pred_edge'])\n",
    "\n",
    "def calculate_f1(df):\n",
    "    return f1_score(df['edge'], df['pred_edge'])\n",
    "\n",
    "def calculate_accuracy(df):\n",
    "    return accuracy_score(df['edge'], df['pred_edge'])\n",
    "\n",
    "def calculate_metrics(df):\n",
    "    recall = calculate_recall(df)\n",
    "    precision = calculate_precision(df)\n",
    "    f1 = calculate_f1(df)\n",
    "    accuracy = calculate_accuracy(df)\n",
    "\n",
    "    return recall, precision, f1, accuracy\n",
    "\n",
    "def calculate_metrics_for_threshold(df, threshold):\n",
    "    df['pred_edge'] = df['prob'].apply(lambda x: 1 if x > threshold else 0)\n",
    "\n",
    "    return calculate_metrics(df)\n",
    "\n",
    "def find_best_threshold(df):\n",
    "    thresholds = np.linspace(0.01, 1, 100)\n",
    "    best_threshold = 0\n",
    "    best_f1 = 0\n",
    "    for threshold in thresholds:\n",
    "        recall, precision, f1, accuracy = calculate_metrics_for_threshold(df, threshold)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_threshold = threshold\n",
    "\n",
    "    return best_threshold, best_f1\n",
    "\n",
    "# recall, precison, f1, accuracy = calculate_metrics(predictions)\n",
    "best_threshold, best_f1 = find_best_threshold(predictions)\n",
    "print(f'Best threshold: {best_threshold}, Best F1: {best_f1}')\n",
    "\n",
    "def create_confusion_matrix(df, threshold):\n",
    "    df['pred_edge'] = df['prob'].apply(lambda x: 1 if x > threshold else 0)\n",
    "\n",
    "    return confusion_matrix(df['edge'], df['pred_edge'])\n",
    "\n",
    "def plot_confusion_matrix(cm):\n",
    "    class_labels = ['Negative Edge', 'Edge']\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_labels))\n",
    "    plt.xticks(tick_marks, class_labels, rotation=45)\n",
    "    plt.yticks(tick_marks, class_labels)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "\n",
    "    for i in range(len(class_labels)):\n",
    "        for j in range(len(class_labels)):\n",
    "            plt.text(j, i, cm[i, j], ha='center', va='center', color='white' if cm[i, j] > cm.max() / 2 else 'black')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "cm = create_confusion_matrix(predictions, best_threshold)\n",
    "plot_confusion_matrix(cm);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def predicted_edges_node_distribution(df):\n",
    "    df['pred_edge'] = df['prob'].apply(lambda x: 1 if x > best_threshold else 0)\n",
    "\n",
    "    return df.groupby('first_node').sum()['pred_edge'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
